from fastapi import FastAPI, HTTPException, Depends
from sqlalchemy import text
from sqlalchemy.ext.asyncio import AsyncSession, create_async_engine, async_sessionmaker
from typing import List, Dict, Any
from datetime import datetime
from fastapi.middleware.cors import CORSMiddleware
from langchain_core.documents import Document
from langchain_core.output_parsers import StrOutputParser
from langchain_core.prompts import PromptTemplate
from langchain_openai import ChatOpenAI
from pydantic import BaseModel
import dotenv
import os
from passlib.context import CryptContext
from sentence_transformers import SentenceTransformer
import numpy as np

# ====================================
# í™˜ê²½ ë³€ìˆ˜ ë¡œë“œ
# ====================================
dotenv.load_dotenv()
DATABASE_URL = os.getenv("DATABASE_URL")
OPENAI_API_KEY = os.getenv("OPENAI_API_KEY")

if not DATABASE_URL:
    raise ValueError("âŒ DATABASE_URL í™˜ê²½ ë³€ìˆ˜ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
if not OPENAI_API_KEY:
    raise ValueError("âŒ OPENAI_API_KEY í™˜ê²½ ë³€ìˆ˜ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")

# ====================================
# FastAPI app
# ====================================
app = FastAPI(title="User Timeline + Weekly Report Service", version="1.0")

# CORS ì„¤ì •
app.add_middleware(
    CORSMiddleware,
    allow_origins=["http://localhost:5173", "http://localhost:5174"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# ====================================
# DB ì—°ê²°
# ====================================
engine = create_async_engine(DATABASE_URL, echo=False)
async_session = async_sessionmaker(engine, class_=AsyncSession)

async def get_db_session():
    async with async_session() as session:
        yield session

# ====================================
# ë°ì´í„° ëª¨ë¸
# ====================================
class TimelineActivity(BaseModel):
    source: str
    timestamp: str
    content: str
    metadata: Dict[str, Any]

class UserTimelineResponse(BaseModel):
    user_id: str
    start_date: str
    end_date: str
    activities: List[TimelineActivity]
    summary: Dict[str, Any]

class ReportRequest(BaseModel):
    start_date: str
    end_date: str
    task_name: str
    admin_request: str

#class ReportResponse(BaseModel):
#    summary: str
class ReportResponse(BaseModel):
    success: bool
    summary: str
    used_reports: List[Dict[str, Any]]  # ì„ íƒëœ ë³´ê³ ì„œ ëª©ë¡
    similarities: List[Dict[str, Any]]  # ê° ë³´ê³ ì„œë³„ ìœ ì‚¬ë„


class ReportIn(BaseModel):
    platform_ids: Dict[str, List[int]]
    start: str
    end: str
    writer: str
    email: str

# ====================================
# ë¹„ë°€ë²ˆí˜¸ ìœ í‹¸
# ====================================
pwd_context = CryptContext(schemes=["bcrypt"], deprecated="auto")

def hash_password(password: str) -> str:
    return pwd_context.hash(password)

def verify_password(plain_password: str, hashed_password: str) -> bool:
    try:
        # bcryptë¡œ ê²€ì¦ ì‹œë„
        return pwd_context.verify(plain_password, hashed_password)
    except Exception:
        # bcryptê°€ ì•„ë‹ˆë©´ í‰ë¬¸ ë¹„êµ
        return plain_password == hashed_password


# ====================================
# ì¸ì¦ìš© ìŠ¤í‚¤ë§ˆ
# ====================================
class EmployeeCreate(BaseModel):
    name: str
    email: str
    password: str

class EmployeeLogin(BaseModel):
    email: str
    password: str

class EmployeeOut(BaseModel):
    id: int
    name: str
    email: str
    class Config:
        orm_mode = True

# ====================================
# LLM
# ====================================
llm = ChatOpenAI(model="gpt-4o", temperature=0.3, api_key=OPENAI_API_KEY)
output_parser = StrOutputParser()

manager_prompt = PromptTemplate.from_template("""
# ì—­í• 
ë‹¹ì‹ ì€ íŒ€ì˜ ì„±ê³¼ë¥¼ í•œëˆˆì— íŒŒì•…í•´ì•¼ í•˜ëŠ” ìœ ëŠ¥í•œ íŒ€ì¥ì…ë‹ˆë‹¤.

# ì§€ì‹œ
ì•„ë˜ì— taskë³„ íŒ€ì›ë“¤ì˜ ì£¼ê°„ ë³´ê³ ì„œë¥¼ ë°”íƒ•ìœ¼ë¡œ, 
**í•µì‹¬ ì„±ê³¼ / ë¬¸ì œì  / ë‹¤ìŒ ì£¼ ê³µí†µ ëª©í‘œ**ë¥¼ ìš”ì•½í•˜ì„¸ìš”.

# íŒ€ì›ë³„ ë³´ê³  ë‚´ìš©
{team_reports}

# ê´€ë¦¬ì ìš”ì•½ ë³´ê³ ì„œ:
""")
manager_chain = manager_prompt | llm | output_parser

# ====================================
# ë³´ê³ ì„œ ì„ë² ë”© ì„œë¹„ìŠ¤
# ====================================
class ReportEmbeddingService:
    """
    ë³´ê³ ì„œ ì„ë² ë”© ì „ìš© ì„œë¹„ìŠ¤ í´ë˜ìŠ¤
    jhgan/ko-sbert-nli ëª¨ë¸ì„ ì‚¬ìš©í•˜ì—¬ 768ì°¨ì› ë²¡í„° ìƒì„±
    """

    def __init__(self):
        """ì„ë² ë”© ëª¨ë¸ ì´ˆê¸°í™”"""
        #self.model_name = "jhgan/ko-sbert-nli"
        self.model_name = "sentence-transformers/all-MiniLM-L6-v2"
        self.model = None
        self._initialize_model()

    def _initialize_model(self):
        """
        SentenceTransformer ëª¨ë¸ ë¡œë“œ
        ìµœì´ˆ ì‹¤í–‰ì‹œ ëª¨ë¸ ë‹¤ìš´ë¡œë“œê°€ í•„ìš”í•  ìˆ˜ ìˆìŒ
        """
        try:
            self.model = SentenceTransformer(self.model_name)
            print(f"âœ… ì„ë² ë”© ëª¨ë¸ ë¡œë“œ ì„±ê³µ: {self.model_name}")
        except Exception as e:
            print(f"âŒ ì„ë² ë”© ëª¨ë¸ ë¡œë“œ ì‹¤íŒ¨: {e}")
            raise

    def create_embedding(self, text: str) -> List[float]:
        """
        í…ìŠ¤íŠ¸ë¥¼ 768ì°¨ì› ë²¡í„°ë¡œ ë³€í™˜

        Args:
            text (str): ì„ë² ë”©í•  í…ìŠ¤íŠ¸ (ë³´ê³ ì„œ ë‚´ìš©)

        Returns:
            List[float]: 768ì°¨ì› ì„ë² ë”© ë²¡í„°
        """
        if not text or not text.strip():
            raise ValueError("ì„ë² ë”©í•  í…ìŠ¤íŠ¸ê°€ ë¹„ì–´ìˆìŠµë‹ˆë‹¤.")

        if self.model is None:
            raise RuntimeError("ì„ë² ë”© ëª¨ë¸ì´ ì´ˆê¸°í™”ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")

        try:
            # í…ìŠ¤íŠ¸ë¥¼ ì„ë² ë”©ìœ¼ë¡œ ë³€í™˜ (768ì°¨ì›)
            embedding = self.model.encode(text.strip())

            # numpy arrayë¥¼ Python listë¡œ ë³€í™˜
            embedding_list = embedding.tolist()

            print(f"ğŸ“Š ì„ë² ë”© ìƒì„± ì™„ë£Œ: {len(embedding_list)}ì°¨ì›")
            return embedding_list

        except Exception as e:
            print(f"âŒ ì„ë² ë”© ìƒì„± ì‹¤íŒ¨: {e}")
            raise

    def create_vector_string(self, embedding: List[float]) -> str:
        """
        ì„ë² ë”© ë¦¬ìŠ¤íŠ¸ë¥¼ PostgreSQL vector í˜•ì‹ ë¬¸ìì—´ë¡œ ë³€í™˜

        Args:
            embedding (List[float]): 768ì°¨ì› ì„ë² ë”© ë²¡í„°

        Returns:
            str: PostgreSQL vector í˜•ì‹ ë¬¸ìì—´ "[0.1,0.2,0.3,...]"
        """
        if not embedding:
            raise ValueError("ì„ë² ë”© ë²¡í„°ê°€ ë¹„ì–´ìˆìŠµë‹ˆë‹¤.")

        if len(embedding) != 384: #768:
            raise ValueError(f"ì„ë² ë”© ì°¨ì›ì´ ì˜¬ë°”ë¥´ì§€ ì•ŠìŠµë‹ˆë‹¤. ì˜ˆìƒ: 384, ì‹¤ì œ: {len(embedding)}")

        # PostgreSQL vector í˜•ì‹ìœ¼ë¡œ ë³€í™˜
        vector_str = "[" + ",".join(map(str, embedding)) + "]"
        return vector_str

# ì„ë² ë”© ì„œë¹„ìŠ¤ ì¸ìŠ¤í„´ìŠ¤ ìƒì„± (ì „ì—­)
embedding_service = ReportEmbeddingService()

REPORT_TEMPLATE = """
## 1) ì£¼ê°„ ìš”ì•½
Task {task_id} ({task_description}) ê´€ë ¨ ì§„í–‰ ìƒí™© ìš”ì•½:
{context}

## 2) ì‚¬ëŒë³„ ì£¼ìš” ì‚°ì¶œë¬¼
{member_list}

## 3) í˜‘ì—… ë‚´ì—­
Slack/Notion/Outlook/OneDrive ê¸°ë¡ ê¸°ë°˜ í˜‘ì—… ë‚´ì—­ ì •ë¦¬.

## 4) ë¦¬ìŠ¤í¬/ì´ìŠˆ
ë¬¸ì œì , ë¦¬ìŠ¤í¬, í•´ê²° í•„ìš” ì‚¬í•­.

## 5) ì°¨ì£¼ ê³„íš
í›„ì† ì‘ì—… ë° ê°œì„ ì .

(ê¸°ê°„: {start} ~ {end})
"""
report_prompt = PromptTemplate(
    template=REPORT_TEMPLATE,
    input_variables=["context", "task_id", "task_description", "member_list", "start", "end"],
)

# ====================================
# ìœ í‹¸ í•¨ìˆ˜
# ====================================
async def get_task_description(task_id: int, session: AsyncSession) -> str:
    query = text("SELECT description FROM public.task WHERE id = :task_id")
    result = await session.execute(query, {"task_id": task_id})
    row = result.fetchone()
    return row[0] if row else "(ì„¤ëª… ì—†ìŒ)"

async def insert_report(task_id: int, writer: str, email: str, content: str, session: AsyncSession) -> int:
    """
    ë³´ê³ ì„œë¥¼ DBì— ì €ì¥í•˜ê³  ìƒì„±ëœ report_idë¥¼ ë°˜í™˜

    Returns:
        int: ìƒì„±ëœ reportì˜ id
    """
    now = datetime.utcnow()
    query = text("""
        INSERT INTO public.report (task_id, "timestamp", writer, email, report)
        VALUES (:task_id, :timestamp, :writer, :email, :content)
        RETURNING id
    """)
    result = await session.execute(query, {
        "task_id": task_id,
        "timestamp": now,
        "writer": writer,
        "email": email,
        "content": content
    })
    report_id = result.fetchone()[0]
    await session.commit()
    return report_id

async def generate_report_with_fallback(task_id: int, platform_data: List[Dict[str, Any]], start_ts: str, end_ts: str, session: AsyncSession) -> str:
    """
    API í‚¤ ìƒíƒœì— ë”°ë¼ ì‹¤ì œ ë³´ê³ ì„œ ë˜ëŠ” ë”ë¯¸ ë³´ê³ ì„œë¥¼ ìƒì„±í•˜ëŠ” wrapper í•¨ìˆ˜

    Args:
        task_id: ì‘ì—… ID
        platform_data: í”Œë«í¼ ë°ì´í„° ë¦¬ìŠ¤íŠ¸
        start_ts: ì‹œì‘ ë‚ ì§œ
        end_ts: ì¢…ë£Œ ë‚ ì§œ
        session: DB ì„¸ì…˜

    Returns:
        str: ìƒì„±ëœ ë³´ê³ ì„œ ë‚´ìš©
    """
    # OpenAI API í‚¤ê°€ ìˆê³  ìœ íš¨í•œì§€ í™•ì¸
    if OPENAI_API_KEY and not OPENAI_API_KEY.startswith("OPENAI_A") and len(OPENAI_API_KEY) >= 20:
        # ì‹¤ì œ OpenAI APIë¥¼ ì‚¬ìš©í•œ ë³´ê³ ì„œ ìƒì„±
        return await generate_report_for_task(task_id, platform_data, start_ts, end_ts, session)
    else:
        # ë”ë¯¸ ë³´ê³ ì„œ ìƒì„± (ì‹¤ì œ ë³´ê³ ì„œ í˜•ì‹ ìœ ì§€)
        print(f"ğŸ”„ OpenAI API í‚¤ê°€ ì—†ì–´ì„œ ë”ë¯¸ ë³´ê³ ì„œë¥¼ ìƒì„±í•©ë‹ˆë‹¤ - Task {task_id}")

        task_description = await get_task_description(task_id, session)
        actors = {d.get("actor") for d in platform_data if d.get("actor")}
        actor_list = "- " + "\n- ".join(actors) if actors else "- (ì°¸ì—¬ì ì—†ìŒ)"

        # ì‹¤ì œ ë³´ê³ ì„œì™€ ë™ì¼í•œ êµ¬ì¡°ë¡œ ë”ë¯¸ ë³´ê³ ì„œ ìƒì„±
        dummy_report = f"""# ì—…ë¬´ {task_id}: {task_description} ì£¼ê°„ ë³´ê³ ì„œ

## 1) ì£¼ê°„ ìš”ì•½
Task {task_id} ({task_description}) ê´€ë ¨ ì§„í–‰ ìƒí™©:
- í”„ë¡œì íŠ¸ê°€ ìˆœì¡°ë¡­ê²Œ ì§„í–‰ë˜ê³  ìˆìŠµë‹ˆë‹¤.
- ì£¼ìš” ê¸°ëŠ¥ ê°œë°œì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤.
- íŒ€ì›ë“¤ê³¼ì˜ í˜‘ì—…ì´ íš¨ê³¼ì ìœ¼ë¡œ ì´ë£¨ì–´ì§€ê³  ìˆìŠµë‹ˆë‹¤.

## 2) ì‚¬ëŒë³„ ì£¼ìš” ì‚°ì¶œë¬¼
{actor_list}

## 3) í˜‘ì—… ë‚´ì—­
íŒ€ì›ë“¤ ê°„ì˜ Slack, Notion, Outlook, OneDriveë¥¼ í†µí•œ íš¨ê³¼ì ì¸ í˜‘ì—…ì´ ì´ë£¨ì–´ì¡ŒìŠµë‹ˆë‹¤.
ì£¼ìš” ì˜ì‚¬ê²°ì •ê³¼ ì§„í–‰ ìƒí™© ê³µìœ ê°€ ì›í™œíˆ ì§„í–‰ë˜ì—ˆìŠµë‹ˆë‹¤.

## 4) ë¦¬ìŠ¤í¬/ì´ìŠˆ
íŠ¹ë³„í•œ ì´ìŠˆ ì—†ì´ ê³„íšëŒ€ë¡œ ì§„í–‰ë˜ì—ˆìŠµë‹ˆë‹¤.
í–¥í›„ ë°œìƒí•  ìˆ˜ ìˆëŠ” ë¦¬ìŠ¤í¬ì— ëŒ€í•œ ëª¨ë‹ˆí„°ë§ì„ ì§€ì†í•˜ê³  ìˆìŠµë‹ˆë‹¤.

## 5) ì°¨ì£¼ ê³„íš
ë‹¤ìŒ ì£¼ì—ëŠ” ì¶”ê°€ ê°œì„  ì‚¬í•­ì„ ë°˜ì˜í•  ì˜ˆì •ì…ë‹ˆë‹¤.
íŒ€ì›ë“¤ê³¼ì˜ ì •ê¸° íšŒì˜ë¥¼ í†µí•´ ì§„í–‰ ìƒí™©ì„ ì ê²€í•  ê³„íšì…ë‹ˆë‹¤.

(ê¸°ê°„: {start_ts} ~ {end_ts})"""

        return dummy_report

async def generate_report_for_task(task_id: int, platform_data: List[Dict[str, Any]], start_ts: str, end_ts: str, session: AsyncSession) -> str:
    docs = [Document(page_content=d.get("content", "")) for d in platform_data]
    actors = {d.get("actor") for d in platform_data if d.get("actor")}
    actor_list = "- " + "\n- ".join(actors) if actors else "- (none)"
    task_description = await get_task_description(task_id, session)
    context = "\n".join([doc.page_content for doc in docs])

    chain = report_prompt | llm | output_parser
    body = await chain.ainvoke({
        "context": context,
        "task_id": task_id,
        "task_description": task_description,
        "member_list": actor_list,
        "start": start_ts,
        "end": end_ts,
    })
    return f"# ì—…ë¬´ {task_id}: {task_description} ì£¼ê°„ ë³´ê³ ì„œ\n\n{body}"

async def store_report_embedding_only(
    report_content: str,
    report_id: int,
    session: AsyncSession
) -> Dict[str, Any]:
    """
    ì´ë¯¸ ì €ì¥ëœ ë³´ê³ ì„œì— ì„ë² ë”©ë§Œ ì¶”ê°€í•˜ëŠ” í•¨ìˆ˜

    Args:
        report_content (str): ë³´ê³ ì„œ ë‚´ìš©
        report_id (int): ì €ì¥ëœ ë³´ê³ ì„œ ID
        session (AsyncSession): DB ì„¸ì…˜

    Returns:
        Dict[str, Any]: ì„ë² ë”© ì €ì¥ ê²°ê³¼ ì •ë³´
    """
    try:
        print(f"ğŸ“Š ì„ë² ë”© ì €ì¥ ì‹œì‘ - Report ID {report_id}")

        # 1. ë³´ê³ ì„œ ì„ë² ë”© ìƒì„±
        embedding_vector = embedding_service.create_embedding(report_content)
        vector_string = embedding_service.create_vector_string(embedding_vector)

        # 2. ê¸°ì¡´ ë³´ê³ ì„œì— ì„ë² ë”© ì—…ë°ì´íŠ¸
        query = text("""
            UPDATE public.report
            SET report_embedded = CAST(:report_embedded AS vector)
            WHERE id = :report_id
        """)

        await session.execute(query, {
            "report_embedded": vector_string,
            "report_id": report_id
        })
        await session.commit()

        print(f"âœ… ì„ë² ë”© ì €ì¥ ì™„ë£Œ - Report ID {report_id}, ì„ë² ë”© ì°¨ì›: {len(embedding_vector)}")

        return {
            "success": True,
            "report_id": report_id,
            "embedding_dimension": len(embedding_vector),
            "report_length": len(report_content)
        }

    except Exception as e:
        print(f"âŒ ì„ë² ë”© ì €ì¥ ì‹¤íŒ¨ - Report ID {report_id}: {e}")
        await session.rollback()
        raise HTTPException(
            status_code=500,
            detail=f"ì„ë² ë”© ì €ì¥ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}"
        )

async def store_report_with_embedding(
    task_id: int,
    report_content: str,
    start_date: str,
    end_date: str,
    writer: str = "system",
    email: str = "system@example.com",
    session: AsyncSession = None
) -> Dict[str, Any]:
    """
    ë³´ê³ ì„œë¥¼ ì„ë² ë”©ê³¼ í•¨ê»˜ DBì— ì €ì¥í•˜ëŠ” í•¨ìˆ˜

    Args:
        task_id (int): ì‘ì—… ID
        report_content (str): ë³´ê³ ì„œ ë‚´ìš©
        start_date (str): ì‹œì‘ ë‚ ì§œ
        end_date (str): ì¢…ë£Œ ë‚ ì§œ
        writer (str): ì‘ì„±ì ì´ë¦„
        email (str): ì‘ì„±ì ì´ë©”ì¼
        session (AsyncSession): DB ì„¸ì…˜

    Returns:
        Dict[str, Any]: ì €ì¥ ê²°ê³¼ ì •ë³´
    """
    try:
        print(f"ğŸ“ ë³´ê³ ì„œ ì €ì¥ ì‹œì‘ - Task {task_id}")

        # 1. ë³´ê³ ì„œ ì„ë² ë”© ìƒì„±
        embedding_vector = embedding_service.create_embedding(report_content)
        vector_string = embedding_service.create_vector_string(embedding_vector)

        # 2. DBì— ë³´ê³ ì„œì™€ ì„ë² ë”© ì €ì¥
        now = datetime.utcnow()
        query = text("""
            INSERT INTO public.report
            (task_id, "timestamp", writer, email, report, report_embedded)
            VALUES
            (:task_id, :timestamp, :writer, :email, :report, CAST(:report_embedded AS vector))
        """)

        await session.execute(query, {
            "task_id": task_id,
            "timestamp": now,
            "writer": writer,
            "email": email,
            "report": report_content,
            "report_embedded": vector_string
        })
        await session.commit()

        print(f"âœ… ë³´ê³ ì„œ ì €ì¥ ì™„ë£Œ - Task {task_id}, ì„ë² ë”© ì°¨ì›: {len(embedding_vector)}")

        return {
            "success": True,
            "task_id": task_id,
            "report_length": len(report_content),
            "embedding_dimension": len(embedding_vector),
            "timestamp": now.isoformat(),
            "period": f"{start_date} ~ {end_date}"
        }

    except Exception as e:
        print(f"âŒ ë³´ê³ ì„œ ì €ì¥ ì‹¤íŒ¨ - Task {task_id}: {e}")
        await session.rollback()
        raise HTTPException(
            status_code=500,
            detail=f"ë³´ê³ ì„œ ì €ì¥ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}"
        )

# ====================================
# API ì—”ë“œí¬ì¸íŠ¸
# ====================================

# --- íšŒì›ê°€ì… ---
@app.post("/signup", response_model=EmployeeOut, tags=["Authentication"])
async def signup(user: EmployeeCreate, session: AsyncSession = Depends(get_db_session)):
    query = text("SELECT id FROM public.employee WHERE email = :email")
    result = await session.execute(query, {"email": user.email})
    if result.fetchone():
        raise HTTPException(status_code=400, detail="ì´ë¯¸ ì¡´ì¬í•˜ëŠ” ì´ë©”ì¼ì…ë‹ˆë‹¤.")

    hashed_pw = hash_password(user.password)
    insert_q = text("""
        INSERT INTO public.employee (name, email, password)
        VALUES (:name, :email, :password)
        RETURNING id, name, email
    """)
    res = await session.execute(insert_q, {"name": user.name, "email": user.email, "password": hashed_pw})
    await session.commit()
    row = res.fetchone()
    return {"id": row[0], "name": row[1], "email": row[2]}

# --- ë¡œê·¸ì¸ ---
@app.post("/login", tags=["Authentication"])
async def login(user: EmployeeLogin, session: AsyncSession = Depends(get_db_session)):
    query = text("SELECT id, name, email, password FROM public.employee WHERE email = :email")
    result = await session.execute(query, {"email": user.email})
    row = result.fetchone()
    if not row or not verify_password(user.password, row[3]):
        raise HTTPException(status_code=400, detail="ì´ë©”ì¼ ë˜ëŠ” ë¹„ë°€ë²ˆí˜¸ê°€ ì˜¬ë°”ë¥´ì§€ ì•ŠìŠµë‹ˆë‹¤.")
    return {"success": True, "user": {"id": row[0], "name": row[1], "email": row[2]}}

# --- íƒ€ì„ë¼ì¸ ì¡°íšŒ ---
@app.get("/api/user-timeline/{email}", response_model=UserTimelineResponse)
async def get_user_timeline(email: str, start_date: str, end_date: str, session: AsyncSession = Depends(get_db_session)):
    start_date_obj = datetime.strptime(start_date, "%Y-%m-%d").date()
    end_date_obj = datetime.strptime(end_date, "%Y-%m-%d").date()

    # 1. email â†’ name ë³€í™˜
    q = text("SELECT name FROM public.employee WHERE email = :email")
    res = await session.execute(q, {"email": email})
    row = res.fetchone()
    if not row:
        raise HTTPException(status_code=404, detail="í•´ë‹¹ ì´ë©”ì¼ì˜ ì‚¬ìš©ìë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
    user_name = row[0]

    activities = []
    counts = {"slack": 0, "notion": 0, "onedrive": 0, "outlook": 0}

    # 2. Slack ì¡°íšŒ (sender/receiverê°€ user_nameì¸ ê²½ìš°)
    slack_query = text("""
        SELECT id, content, sender, receiver, task_id, "timestamp"::text as timestamp
        FROM public.slack
        WHERE (sender = :user_name OR receiver = :user_name)
          AND DATE("timestamp") BETWEEN :start_date AND :end_date
        ORDER BY "timestamp" DESC
    """)
    slack_result = await session.execute(
        slack_query,
        {"user_name": user_name, "start_date": start_date_obj, "end_date": end_date_obj}
    )
    for row in slack_result.fetchall():
        r = dict(row._mapping)
        activities.append(TimelineActivity(
            source="slack",
            timestamp=r["timestamp"],
            content=r["content"],
            metadata={
                "sender": r["sender"],
                "receiver": r["receiver"],
                "task_id": r["task_id"],
                "slack_id": r["id"],
                "id": r["id"]
            }
        ))
        counts["slack"] += 1

    # 3. Notion ì¡°íšŒ (participant_idê°€ user_nameì¸ ê²½ìš°)
    notion_query = text("""
        SELECT id, content, participant_id, task_id, "timestamp"::text as timestamp
        FROM public.notion
        WHERE participant_id = :user_name
          AND DATE("timestamp") BETWEEN :start_date AND :end_date
        ORDER BY "timestamp" DESC
    """)
    notion_result = await session.execute(
        notion_query,
        {"user_name": user_name, "start_date": start_date_obj, "end_date": end_date_obj}
    )
    for row in notion_result.fetchall():
        r = dict(row._mapping)
        activities.append(TimelineActivity(
            source="notion",
            timestamp=r["timestamp"],
            content=r["content"],
            metadata={
                "sender": r["participant_id"],  # ì‘ì„±ìë¡œ í‘œì‹œ
                "receiver": "-",  # Notionì€ ìˆ˜ì‹ ì ì—†ìŒ
                "task_id": r["task_id"],
                "notion_id": r["id"],
                "id": r["id"]
            }
        ))
        counts["notion"] += 1

    # 4. OneDrive ì¡°íšŒ (writerê°€ user_nameì¸ ê²½ìš°)
    onedrive_query = text("""
        SELECT id, content, writer, task_id, "timestamp"::text as timestamp
        FROM public.onedrive
        WHERE writer = :user_name
          AND DATE("timestamp") BETWEEN :start_date AND :end_date
        ORDER BY "timestamp" DESC
    """)
    onedrive_result = await session.execute(
        onedrive_query,
        {"user_name": user_name, "start_date": start_date_obj, "end_date": end_date_obj}
    )
    for row in onedrive_result.fetchall():
        r = dict(row._mapping)
        activities.append(TimelineActivity(
            source="onedrive",
            timestamp=r["timestamp"],
            content=r["content"],
            metadata={
                "sender": r["writer"],  # ì‘ì„±ìë¡œ í‘œì‹œ
                "receiver": "-",  # OneDriveëŠ” ìˆ˜ì‹ ì ì—†ìŒ
                "task_id": r["task_id"],
                "onedrive_id": r["id"],
                "id": r["id"]
            }
        ))
        counts["onedrive"] += 1

    # 5. Outlook ì¡°íšŒ (sender/receiverê°€ user_nameì¸ ê²½ìš°)
    outlook_query = text("""
        SELECT id, content, sender, receiver, task_id, "timestamp"::text as timestamp
        FROM public.outlook
        WHERE (sender = :user_name OR receiver = :user_name)
          AND DATE("timestamp") BETWEEN :start_date AND :end_date
        ORDER BY "timestamp" DESC
    """)
    outlook_result = await session.execute(
        outlook_query,
        {"user_name": user_name, "start_date": start_date_obj, "end_date": end_date_obj}
    )
    for row in outlook_result.fetchall():
        r = dict(row._mapping)
        activities.append(TimelineActivity(
            source="outlook",
            timestamp=r["timestamp"],
            content=r["content"],
            metadata={
                "sender": r["sender"],
                "receiver": r["receiver"],
                "task_id": r["task_id"],
                "outlook_id": r["id"],
                "id": r["id"]
            }
        ))
        counts["outlook"] += 1

    # ì‹œê°„ìˆœ ì •ë ¬
    activities.sort(key=lambda x: x.timestamp, reverse=True)

    return UserTimelineResponse(
        user_id=email,
        start_date=start_date,
        end_date=end_date,
        activities=activities,
        summary={"total_count": len(activities), **counts}
    )


# --- í™œë™ ìš”ì•½ ---
@app.get("/api/user-summary/{email}")
async def get_user_summary(email: str, start_date: str, end_date: str, session: AsyncSession = Depends(get_db_session)):
    q = text("SELECT name FROM public.employee WHERE email = :email")
    res = await session.execute(q, {"email": email})
    row = res.fetchone()
    if not row:
        raise HTTPException(status_code=404, detail="í•´ë‹¹ ì´ë©”ì¼ì˜ ì‚¬ìš©ìë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
    user_name = row[0]

    start_date_obj = datetime.strptime(start_date, "%Y-%m-%d").date()
    end_date_obj = datetime.strptime(end_date, "%Y-%m-%d").date()

    query = text("""
        SELECT COUNT(*) 
        FROM public.slack
        WHERE (sender = :user_name OR receiver = :user_name)
          AND DATE("timestamp") BETWEEN :start_date AND :end_date
    """)
    result = await session.execute(query, {"user_name": user_name, "start_date": start_date_obj, "end_date": end_date_obj})
    count = result.scalar()
    return {"email": email, "user_name": user_name, "total_count": count}

# --- ì‚¬ìš©ì ëª©ë¡ ---
@app.get("/api/users")
async def get_available_users(session: AsyncSession = Depends(get_db_session)):
    query = text("SELECT DISTINCT name FROM public.employee ORDER BY name")
    result = await session.execute(query)
    users = [row[0] for row in result.fetchall()]
    return {"users": users, "count": len(users)}

# --- DB health ---
@app.get("/api/db-health")
async def db_health(session: AsyncSession = Depends(get_db_session)):
    try:
        result = await session.execute(text("SELECT 1"))
        return {"database_status": "connected", "result": result.scalar()}
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))

# --- ì„œë¹„ìŠ¤ health ---
@app.get("/health")
async def health_check():
    return {"status": "healthy"}

# --- ìš”ì•½ ìƒì„± ---
#@app.post("/api/generate-summary", response_model=ReportResponse)
#async def generate_summary(request: ReportRequest):
#    """ê¸°ì¡´ ê´€ë¦¬ì ìš”ì•½API (ê¸°ì¡´ ê¸°ëŠ¥ ìœ ì§€)"""
#    dummy_reports = f"Task {request.task_id} ë³´ê³ ì„œ (ê¸°ê°„ {request.start_date}~{request.end_date})"
#    manager_summary = await manager_chain.ainvoke({"team_reports": dummy_reports})
#    return ReportResponse(summary=manager_summary)

from sqlalchemy import text
import numpy as np

# --- ìš”ì•½ ìƒì„± - ì†Œí˜„ 0927 ---
@app.post("/api/generate-summary", response_model=ReportResponse)
async def generate_summary(request: ReportRequest, session: AsyncSession = Depends(get_db_session)):
    """ê´€ë¦¬ì ìš”ì•½ API (ì„ë² ë”© + ì½”ì‚¬ì¸ ìœ ì‚¬ë„ ê¸°ë°˜ + ë””ë²„ê¹… ì •ë³´ í¬í•¨)"""

    task_mapping = {
        "í”„ë¡œì íŠ¸ 1: ì˜¨ë¼ì¸ ì‡¼í•‘ëª° ì‹œìŠ¤í…œ êµ¬ì¶•": 1,
        "í”„ë¡œì íŠ¸ 2: ë³‘ì› ì˜ˆì•½Â·ì§„ë£Œ ì‹œìŠ¤í…œ í†µí•©": 2,
    }
    task_id = task_mapping.get(request.task_name)
    if not task_id:
        raise HTTPException(status_code=400, detail="task_nameì´ ì˜¬ë°”ë¥´ì§€ ì•ŠìŠµë‹ˆë‹¤.")

    # 1. admin_request ì„ë² ë”© ìƒì„±
    request_embedded = embedding_service.create_embedding(request.admin_request)
    request_embedded = np.array(request_embedded, dtype=np.float32)

    # 2. í•´ë‹¹ task_id ë³´ê³ ì„œ ì¡°íšŒ
    query = text("""
        SELECT id, report, report_embedded
        FROM public.report
        WHERE task_id = :task_id
    """)
    result = await session.execute(query, {"task_id": task_id})
    rows = result.fetchall()

    if not rows:
        return ReportResponse(
            success=False,
            summary="âŒ í•´ë‹¹ task_idì— ì €ì¥ëœ ë³´ê³ ì„œê°€ ì—†ìŠµë‹ˆë‹¤.",
            used_reports=[],
            similarities=[]
        )

    reports_for_summary = []
    similarities = []

    for row in rows:
        rep_id = row[0]
        rep_content = row[1]
        rep_emb_str = row[2]

        if not rep_emb_str:
            continue

        # PostgreSQL vector â†’ numpy array
        rep_emb = np.array(
            list(map(float, rep_emb_str.strip("[]").split(","))),
            dtype=np.float32
        )

        # cosine similarity ê³„ì‚°
        cosine_sim = float(
            np.dot(request_embedded, rep_emb) /
            (np.linalg.norm(request_embedded) * np.linalg.norm(rep_emb))
        )

        similarities.append({
            "report_id": rep_id,
            "similarity": cosine_sim
        })

        if cosine_sim >= 0.3:
            reports_for_summary.append({
                "report_id": rep_id,
                "content": rep_content,
                "similarity": cosine_sim
            })

    # context_summary ìƒì„±
    if reports_for_summary:
        context_summary = "\n".join([r["content"] for r in reports_for_summary])
    else:
        context_summary = "âš ï¸ ìœ ì‚¬ë„ê°€ 0.3 ì´ìƒì¸ ë³´ê³ ì„œê°€ ì—†ìŠµë‹ˆë‹¤."

    # LLM ìš”ì•½ ì‹¤í–‰
    manager_summary = await manager_chain.ainvoke({"team_reports": context_summary})

    return ReportResponse(
        success=True,
        summary=manager_summary,
        used_reports=reports_for_summary,
        similarities=similarities
    )

# --- ì£¼ê°„ ë³´ê³ ì„œ ìƒì„± + ì„ë² ë”© ì €ì¥ ---
@app.post("/reports/weekly")
async def make_weekly_report(p: ReportIn, session: AsyncSession = Depends(get_db_session)):
    """
    ì£¼ê°„ ë³´ê³ ì„œ ìƒì„± ë° ì„ë² ë”© ì €ì¥ API

    íë¦„:
    1. í”Œë«í¼ë³„ ë°ì´í„° ìˆ˜ì§‘ (Slack, Notion, Outlook, OneDrive)
    2. task_idë³„ë¡œ ë°ì´í„° ê·¸ë£¹í•‘
    3. ë³´ê³ ì„œ ìƒì„± (generate_report_with_fallback ì‚¬ìš©)
       - OpenAI API í‚¤ ìˆìŒ: ì‹¤ì œ LLM ë³´ê³ ì„œ ìƒì„±
       - OpenAI API í‚¤ ì—†ìŒ: ë”ë¯¸ ë³´ê³ ì„œ ìƒì„± (ì„ì‹œ, í”„ë¡œë•ì…˜ì—ì„œ ì œê±° í•„ìš”)
    4. ë³´ê³ ì„œ DB ì €ì¥ (insert_report)
    5. ì„ë² ë”© ìƒì„± ë° ì €ì¥ (store_report_embedding_only)
       - jhgan/ko-sbert-nli ëª¨ë¸ ì‚¬ìš© (768ì°¨ì›)
       - PostgreSQL vector íƒ€ì…ìœ¼ë¡œ ì €ì¥

    Args:
        p (ReportIn): í”Œë«í¼ë³„ ID ëª©ë¡, ê¸°ê°„, ì‘ì„±ì ì •ë³´

    Returns:
        dict: ìƒì„±ëœ ë³´ê³ ì„œ ëª©ë¡ ë° ë©”íƒ€ë°ì´í„°

    Note:
        - ë”ë¯¸ ë³´ê³ ì„œëŠ” ê°œë°œ/í…ŒìŠ¤íŠ¸ìš©ì´ë©° í”„ë¡œë•ì…˜ì—ì„œëŠ” ì œê±° ì˜ˆì •
    """
    reports = []

    # 1. ëª¨ë“  í”Œë«í¼ ë°ì´í„° ìˆ˜ì§‘
    all_platform_data = []
    for platform, ids in p.platform_ids.items():
        if not ids:
            continue

        query = None
        if platform == "slack":
            query = text("SELECT id, content, sender AS actor, receiver, task_id, \"timestamp\"::text as ts FROM public.slack WHERE id = ANY(:ids)")
        elif platform == "notion":
            query = text("SELECT id, content, NULL as actor, task_id, \"timestamp\"::text as ts FROM public.notion WHERE id = ANY(:ids)")
        elif platform == "outlook":
            query = text("SELECT id, content, sender AS actor, receiver, task_id, \"timestamp\"::text as ts FROM public.outlook WHERE id = ANY(:ids)")
        elif platform == "onedrive":
            query = text("SELECT id, content, writer AS actor, task_id, \"timestamp\"::text as ts FROM public.onedrive WHERE id = ANY(:ids)")

        # âœ… ì—¬ê¸° ìˆ˜ì •ë¨
        if query is not None:
            result = await session.execute(query, {"ids": ids})
            rows = [dict(r._mapping) for r in result.fetchall()]
            all_platform_data.extend(rows)

    # 2. task_idë³„ ê·¸ë£¹í•‘
    grouped = {}
    for d in all_platform_data:
        task_id = d.get("task_id")
        if not task_id:
            continue
        grouped.setdefault(task_id, []).append(d)

    # 3. ë³´ê³ ì„œ ìƒì„±
    for task_id, items in grouped.items():
        task_id_int = int(task_id)

        # ë³´ê³ ì„œ ìƒì„± (API í‚¤ ìƒíƒœì— ë”°ë¼ ìë™ ë¶„ê¸°)
        report_md = await generate_report_with_fallback(task_id_int, items, p.start, p.end, session)

        # ë³´ê³ ì„œ ì €ì¥ (report_id ë°˜í™˜)
        report_id = await insert_report(task_id_int, p.writer, p.email, report_md, session)

        # ì„ë² ë”© ìƒì„± ë° ì €ì¥
        await store_report_embedding_only(report_md, report_id, session)

        reports.append({"task_id": task_id_int, "report": report_md})

    return {
        "platform_ids": p.platform_ids,
        "range": {"start": p.start, "end": p.end},
        "reports": reports
    }


# ====================================
# ì‹¤í–‰
# ====================================
if __name__ == "__main__":
    import uvicorn
    uvicorn.run(app, host="0.0.0.0", port=8001, reload=False)
